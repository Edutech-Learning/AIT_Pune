{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7 - Sequence to Sequence Learning for Addition of Two Numbers\n",
    "In this example, we train a model to learn to add two numbers, provided as strings.\n",
    "Example:\n",
    "\n",
    "-    Input: \"512+23\"\n",
    "-    Output: \"535\"\n",
    "\n",
    "Input may optionally be reversed, which was shown to increase performance. Theoretically, sequence order inversion introduces shorter term dependencies between source and target for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dependencies\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "REVERSE = True\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '323+562'). Maximum length of\n",
    "# int is DIGITS.\n",
    "MAXLEN = DIGITS + 1 + DIGITS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total questions: 50000\n"
     ]
    }
   ],
   "source": [
    "class CharacterTable:\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one-hot integer representation\n",
    "    + Decode the one-hot or integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One-hot encode given string C.\n",
    "        # Arguments\n",
    "            C: string, to be encoded.\n",
    "            num_rows: Number of rows in the returned one-hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        \"\"\"Decode the given vector or 2D array to their character output.\n",
    "        # Arguments\n",
    "            x: A vector or a 2D array of probabilities or one-hot representations;\n",
    "                or a vector of character indices (used with `calc_argmax=False`).\n",
    "            calc_argmax: Whether to find the character index with maximum\n",
    "                probability, defaults to `True`.\n",
    "        \"\"\"\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return \"\".join(self.indices_char[x] for x in x)\n",
    "\n",
    "\n",
    "# All the numbers, plus sign and space for padding.\n",
    "chars = \"0123456789+ \"\n",
    "ctable = CharacterTable(chars)\n",
    "\n",
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "print(\"Generating data...\")\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: int(\n",
    "        \"\".join(\n",
    "            np.random.choice(list(\"0123456789\"))\n",
    "            for i in range(np.random.randint(1, DIGITS + 1))\n",
    "        )\n",
    "    )\n",
    "    a, b = f(), f()\n",
    "    # Skip any addition questions we've already seen\n",
    "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    # Pad the data with spaces such that it is always MAXLEN.\n",
    "    q = \"{}+{}\".format(a, b)\n",
    "    query = q + \" \" * (MAXLEN - len(q))\n",
    "    ans = str(a + b)\n",
    "    # Answers can be of maximum size DIGITS + 1.\n",
    "    ans += \" \" * (DIGITS + 1 - len(ans))\n",
    "    if REVERSE:\n",
    "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "        # space used for padding.)\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print(\"Total questions:\", len(questions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "Training Data:\n",
      "(45000, 7, 12)\n",
      "(45000, 4, 12)\n",
      "Validation Data:\n",
      "(5000, 7, 12)\n",
      "(5000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"Vectorization...\")\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
    "\n",
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "# digits.\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "print(\"Training Data:\")\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"Validation Data:\")\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 128)               72192     \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 4, 128)            131584    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4, 12)             1548      \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"Build model...\")\n",
    "num_layers = 1  # Try to add more LSTM layers!\n",
    "\n",
    "model = keras.Sequential()\n",
    "# \"Encode\" the input sequence using a LSTM, producing an output of size 128.\n",
    "# Note: In a situation where your input sequences have a variable length,\n",
    "# use input_shape=(None, num_feature).\n",
    "model.add(layers.LSTM(128, input_shape=(MAXLEN, len(chars))))\n",
    "# As the decoder RNN's input, repeatedly provide with the last output of\n",
    "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
    "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "# The decoder RNN could be multiple layers stacked or a single layer.\n",
    "for _ in range(num_layers):\n",
    "    # By setting return_sequences to True, return not only the last output but\n",
    "    # all the outputs so far in the form of (num_samples, timesteps,\n",
    "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
    "    # the first dimension to be the timesteps.\n",
    "    model.add(layers.LSTM(128, return_sequences=True))\n",
    "\n",
    "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
    "# of the output sequence, decide which character should be chosen.\n",
    "model.add(layers.Dense(len(chars), activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 1\n",
      "1407/1407 [==============================] - 33s 24ms/step - loss: 1.7613 - accuracy: 0.3549 - val_loss: 1.5918 - val_accuracy: 0.4069\n",
      "Q 852+374 T 1226 ☒ 1222\n",
      "Q 286+96  T 382  ☒ 282 \n",
      "Q 136+472 T 608  ☒ 778 \n",
      "Q 655+172 T 827  ☒ 808 \n",
      "Q 637+321 T 958  ☒ 808 \n",
      "Q 776+82  T 858  ☒ 872 \n",
      "Q 77+160  T 237  ☒ 278 \n",
      "Q 492+4   T 496  ☒ 44  \n",
      "Q 54+88   T 142  ☒ 141 \n",
      "Q 92+547  T 639  ☒ 902 \n",
      "\n",
      "Iteration 2\n",
      "1407/1407 [==============================] - 34s 24ms/step - loss: 1.3821 - accuracy: 0.4825 - val_loss: 1.2097 - val_accuracy: 0.5493\n",
      "Q 827+596 T 1423 ☒ 1425\n",
      "Q 789+65  T 854  ☒ 861 \n",
      "Q 382+8   T 390  ☑ 390 \n",
      "Q 0+657   T 657  ☒ 665 \n",
      "Q 471+315 T 786  ☒ 765 \n",
      "Q 4+942   T 946  ☒ 952 \n",
      "Q 13+145  T 158  ☒ 155 \n",
      "Q 471+561 T 1032 ☒ 905 \n",
      "Q 216+230 T 446  ☒ 462 \n",
      "Q 604+817 T 1421 ☒ 1411\n",
      "\n",
      "Iteration 3\n",
      "1407/1407 [==============================] - 35s 25ms/step - loss: 1.0680 - accuracy: 0.6033 - val_loss: 0.9771 - val_accuracy: 0.6329\n",
      "Q 349+112 T 461  ☒ 457 \n",
      "Q 853+23  T 876  ☒ 885 \n",
      "Q 889+799 T 1688 ☒ 1755\n",
      "Q 187+297 T 484  ☒ 546 \n",
      "Q 780+807 T 1587 ☒ 1615\n",
      "Q 619+57  T 676  ☒ 688 \n",
      "Q 153+844 T 997  ☒ 905 \n",
      "Q 928+80  T 1008 ☒ 1003\n",
      "Q 61+479  T 540  ☒ 544 \n",
      "Q 958+31  T 989  ☒ 998 \n",
      "\n",
      "Iteration 4\n",
      "1407/1407 [==============================] - 34s 24ms/step - loss: 0.8837 - accuracy: 0.6745 - val_loss: 0.8755 - val_accuracy: 0.6694\n",
      "Q 336+289 T 625  ☒ 618 \n",
      "Q 58+581  T 639  ☒ 638 \n",
      "Q 923+360 T 1283 ☒ 1288\n",
      "Q 129+80  T 209  ☒ 207 \n",
      "Q 77+981  T 1058 ☒ 1067\n",
      "Q 295+779 T 1074 ☒ 1078\n",
      "Q 584+502 T 1086 ☒ 1188\n",
      "Q 63+388  T 451  ☒ 441 \n",
      "Q 13+155  T 168  ☒ 178 \n",
      "Q 23+316  T 339  ☒ 337 \n",
      "\n",
      "Iteration 5\n",
      "1407/1407 [==============================] - 34s 24ms/step - loss: 0.7716 - accuracy: 0.7181 - val_loss: 0.7270 - val_accuracy: 0.7387\n",
      "Q 173+751 T 924  ☒ 928 \n",
      "Q 1+711   T 712  ☑ 712 \n",
      "Q 348+0   T 348  ☒ 349 \n",
      "Q 741+43  T 784  ☒ 780 \n",
      "Q 857+34  T 891  ☒ 890 \n",
      "Q 611+59  T 670  ☑ 670 \n",
      "Q 59+852  T 911  ☒ 901 \n",
      "Q 619+242 T 861  ☑ 861 \n",
      "Q 39+721  T 760  ☒ 758 \n",
      "Q 973+31  T 1004 ☒ 1002\n",
      "\n",
      "Iteration 6\n",
      "1407/1407 [==============================] - 33s 23ms/step - loss: 0.6823 - accuracy: 0.7535 - val_loss: 0.6417 - val_accuracy: 0.7721\n",
      "Q 223+44  T 267  ☒ 265 \n",
      "Q 56+8    T 64   ☑ 64  \n",
      "Q 915+28  T 943  ☒ 942 \n",
      "Q 6+997   T 1003 ☒ 1005\n",
      "Q 477+10  T 487  ☒ 485 \n",
      "Q 390+332 T 722  ☒ 727 \n",
      "Q 83+32   T 115  ☒ 116 \n",
      "Q 656+7   T 663  ☑ 663 \n",
      "Q 179+739 T 918  ☒ 915 \n",
      "Q 387+211 T 598  ☒ 592 \n",
      "\n",
      "Iteration 7\n",
      "1407/1407 [==============================] - 33s 23ms/step - loss: 0.5664 - accuracy: 0.7956 - val_loss: 0.4614 - val_accuracy: 0.8270\n",
      "Q 706+803 T 1509 ☒ 1508\n",
      "Q 30+605  T 635  ☒ 637 \n",
      "Q 72+53   T 125  ☒ 126 \n",
      "Q 972+95  T 1067 ☒ 1068\n",
      "Q 41+871  T 912  ☒ 915 \n",
      "Q 671+515 T 1186 ☑ 1186\n",
      "Q 874+504 T 1378 ☑ 1378\n",
      "Q 517+930 T 1447 ☑ 1447\n",
      "Q 467+994 T 1461 ☑ 1461\n",
      "Q 255+129 T 384  ☒ 385 \n",
      "\n",
      "Iteration 8\n",
      "1407/1407 [==============================] - 33s 24ms/step - loss: 0.3204 - accuracy: 0.8981 - val_loss: 0.2153 - val_accuracy: 0.9474\n",
      "Q 349+862 T 1211 ☑ 1211\n",
      "Q 953+870 T 1823 ☑ 1823\n",
      "Q 687+11  T 698  ☑ 698 \n",
      "Q 76+988  T 1064 ☑ 1064\n",
      "Q 398+90  T 488  ☒ 487 \n",
      "Q 23+476  T 499  ☑ 499 \n",
      "Q 817+17  T 834  ☑ 834 \n",
      "Q 74+153  T 227  ☑ 227 \n",
      "Q 41+23   T 64   ☑ 64  \n",
      "Q 884+6   T 890  ☑ 890 \n",
      "\n",
      "Iteration 9\n",
      "1407/1407 [==============================] - 33s 23ms/step - loss: 0.1734 - accuracy: 0.9579 - val_loss: 0.1165 - val_accuracy: 0.9786\n",
      "Q 88+393  T 481  ☑ 481 \n",
      "Q 201+47  T 248  ☑ 248 \n",
      "Q 557+57  T 614  ☑ 614 \n",
      "Q 366+963 T 1329 ☑ 1329\n",
      "Q 972+96  T 1068 ☑ 1068\n",
      "Q 50+67   T 117  ☑ 117 \n",
      "Q 158+76  T 234  ☑ 234 \n",
      "Q 37+51   T 88   ☑ 88  \n",
      "Q 82+33   T 115  ☑ 115 \n",
      "Q 170+8   T 178  ☑ 178 \n",
      "\n",
      "Iteration 10\n",
      "1407/1407 [==============================] - 33s 23ms/step - loss: 0.1004 - accuracy: 0.9782 - val_loss: 0.0850 - val_accuracy: 0.9796\n",
      "Q 7+9     T 16   ☑ 16  \n",
      "Q 458+2   T 460  ☑ 460 \n",
      "Q 9+925   T 934  ☒ 933 \n",
      "Q 636+211 T 847  ☑ 847 \n",
      "Q 19+174  T 193  ☑ 193 \n",
      "Q 0+341   T 341  ☒ 332 \n",
      "Q 65+679  T 744  ☑ 744 \n",
      "Q 594+847 T 1441 ☑ 1441\n",
      "Q 731+95  T 826  ☑ 826 \n",
      "Q 360+18  T 378  ☑ 378 \n",
      "\n",
      "Iteration 11\n",
      "1407/1407 [==============================] - 33s 23ms/step - loss: 0.0767 - accuracy: 0.9815 - val_loss: 0.0842 - val_accuracy: 0.9754\n",
      "Q 49+614  T 663  ☑ 663 \n",
      "Q 46+695  T 741  ☑ 741 \n",
      "Q 93+33   T 126  ☑ 126 \n",
      "Q 130+537 T 667  ☑ 667 \n",
      "Q 36+236  T 272  ☑ 272 \n",
      "Q 575+641 T 1216 ☑ 1216\n",
      "Q 134+3   T 137  ☑ 137 \n",
      "Q 453+10  T 463  ☑ 463 \n",
      "Q 72+508  T 580  ☒ 570 \n",
      "Q 69+880  T 949  ☑ 949 \n",
      "\n",
      "Iteration 12\n",
      "1407/1407 [==============================] - 33s 23ms/step - loss: 0.0531 - accuracy: 0.9876 - val_loss: 0.0783 - val_accuracy: 0.9758\n",
      "Q 77+668  T 745  ☑ 745 \n",
      "Q 686+6   T 692  ☑ 692 \n",
      "Q 71+145  T 216  ☑ 216 \n",
      "Q 199+240 T 439  ☑ 439 \n",
      "Q 228+654 T 882  ☑ 882 \n",
      "Q 28+442  T 470  ☒ 460 \n",
      "Q 552+913 T 1465 ☑ 1465\n",
      "Q 894+207 T 1101 ☒ 1001\n",
      "Q 918+464 T 1382 ☑ 1382\n",
      "Q 754+590 T 1344 ☑ 1344\n",
      "\n",
      "Iteration 13\n",
      "1407/1407 [==============================] - 33s 23ms/step - loss: 0.0454 - accuracy: 0.9890 - val_loss: 0.0770 - val_accuracy: 0.9761\n",
      "Q 85+998  T 1083 ☒ 1093\n",
      "Q 286+96  T 382  ☑ 382 \n",
      "Q 826+63  T 889  ☑ 889 \n",
      "Q 821+648 T 1469 ☒ 1479\n",
      "Q 59+515  T 574  ☑ 574 \n",
      "Q 456+606 T 1062 ☑ 1062\n",
      "Q 447+4   T 451  ☑ 451 \n",
      "Q 544+158 T 702  ☑ 702 \n",
      "Q 111+718 T 829  ☑ 829 \n",
      "Q 295+54  T 349  ☑ 349 \n",
      "\n",
      "Iteration 14\n",
      "1407/1407 [==============================] - 33s 23ms/step - loss: 0.0442 - accuracy: 0.9881 - val_loss: 0.0291 - val_accuracy: 0.9937\n",
      "Q 16+398  T 414  ☑ 414 \n",
      "Q 967+517 T 1484 ☑ 1484\n",
      "Q 919+22  T 941  ☑ 941 \n",
      "Q 904+31  T 935  ☑ 935 \n",
      "Q 71+397  T 468  ☑ 468 \n",
      "Q 85+998  T 1083 ☑ 1083\n",
      "Q 34+914  T 948  ☑ 948 \n",
      "Q 849+0   T 849  ☑ 849 \n",
      "Q 52+864  T 916  ☑ 916 \n",
      "Q 49+579  T 628  ☑ 628 \n",
      "\n",
      "Iteration 15\n",
      "1407/1407 [==============================] - 33s 24ms/step - loss: 0.0322 - accuracy: 0.9916 - val_loss: 0.0169 - val_accuracy: 0.9970\n",
      "Q 54+741  T 795  ☑ 795 \n",
      "Q 50+45   T 95   ☑ 95  \n",
      "Q 921+356 T 1277 ☑ 1277\n",
      "Q 874+4   T 878  ☑ 878 \n",
      "Q 246+8   T 254  ☑ 254 \n",
      "Q 9+402   T 411  ☑ 411 \n",
      "Q 658+868 T 1526 ☑ 1526\n",
      "Q 9+28    T 37   ☑ 37  \n",
      "Q 765+537 T 1302 ☑ 1302\n",
      "Q 66+72   T 138  ☑ 138 \n",
      "\n",
      "Iteration 16\n",
      "1407/1407 [==============================] - 33s 24ms/step - loss: 0.0330 - accuracy: 0.9915 - val_loss: 0.0150 - val_accuracy: 0.9974\n",
      "Q 561+68  T 629  ☑ 629 \n",
      "Q 13+302  T 315  ☑ 315 \n",
      "Q 801+312 T 1113 ☑ 1113\n",
      "Q 607+7   T 614  ☑ 614 \n",
      "Q 694+81  T 775  ☑ 775 \n",
      "Q 84+584  T 668  ☑ 668 \n",
      "Q 1+711   T 712  ☑ 712 \n",
      "Q 316+5   T 321  ☑ 321 \n",
      "Q 25+91   T 116  ☑ 116 \n",
      "Q 41+313  T 354  ☑ 354 \n",
      "\n",
      "Iteration 17\n",
      "1407/1407 [==============================] - 35s 25ms/step - loss: 0.0294 - accuracy: 0.9922 - val_loss: 0.0138 - val_accuracy: 0.9978\n",
      "Q 318+96  T 414  ☑ 414 \n",
      "Q 546+45  T 591  ☑ 591 \n",
      "Q 5+673   T 678  ☑ 678 \n",
      "Q 540+463 T 1003 ☑ 1003\n",
      "Q 124+421 T 545  ☑ 545 \n",
      "Q 884+614 T 1498 ☑ 1498\n",
      "Q 8+38    T 46   ☑ 46  \n",
      "Q 297+8   T 305  ☑ 305 \n",
      "Q 507+598 T 1105 ☑ 1105\n",
      "Q 891+639 T 1530 ☑ 1530\n",
      "\n",
      "Iteration 18\n",
      "1407/1407 [==============================] - 33s 23ms/step - loss: 0.0193 - accuracy: 0.9952 - val_loss: 0.0457 - val_accuracy: 0.9862\n",
      "Q 569+9   T 578  ☑ 578 \n",
      "Q 147+442 T 589  ☑ 589 \n",
      "Q 603+8   T 611  ☑ 611 \n",
      "Q 368+393 T 761  ☑ 761 \n",
      "Q 946+985 T 1931 ☒ 1941\n",
      "Q 252+54  T 306  ☑ 306 \n",
      "Q 305+83  T 388  ☑ 388 \n",
      "Q 86+243  T 329  ☑ 329 \n",
      "Q 793+917 T 1710 ☑ 1710\n",
      "Q 446+929 T 1375 ☑ 1375\n",
      "\n",
      "Iteration 19\n",
      "1407/1407 [==============================] - 33s 23ms/step - loss: 0.0332 - accuracy: 0.9908 - val_loss: 0.0086 - val_accuracy: 0.9984\n",
      "Q 71+596  T 667  ☑ 667 \n",
      "Q 755+689 T 1444 ☑ 1444\n",
      "Q 583+626 T 1209 ☑ 1209\n",
      "Q 774+55  T 829  ☑ 829 \n",
      "Q 86+203  T 289  ☑ 289 \n",
      "Q 109+93  T 202  ☑ 202 \n",
      "Q 44+870  T 914  ☑ 914 \n",
      "Q 1+647   T 648  ☑ 648 \n",
      "Q 642+25  T 667  ☑ 667 \n",
      "Q 643+4   T 647  ☑ 647 \n",
      "\n",
      "Iteration 20\n",
      "1407/1407 [==============================] - 26s 18ms/step - loss: 0.0285 - accuracy: 0.9919 - val_loss: 0.0437 - val_accuracy: 0.9855\n",
      "Q 561+867 T 1428 ☑ 1428\n",
      "Q 25+394  T 419  ☑ 419 \n",
      "Q 12+743  T 755  ☑ 755 \n",
      "Q 6+536   T 542  ☑ 542 \n",
      "Q 550+843 T 1393 ☑ 1393\n",
      "Q 298+55  T 353  ☑ 353 \n",
      "Q 455+168 T 623  ☑ 623 \n",
      "Q 8+319   T 327  ☑ 327 \n",
      "Q 6+541   T 547  ☑ 547 \n",
      "Q 211+74  T 285  ☑ 285 \n",
      "\n",
      "Iteration 21\n",
      "1407/1407 [==============================] - 32s 23ms/step - loss: 0.0177 - accuracy: 0.9957 - val_loss: 0.0074 - val_accuracy: 0.9989\n",
      "Q 345+88  T 433  ☑ 433 \n",
      "Q 179+640 T 819  ☑ 819 \n",
      "Q 226+92  T 318  ☑ 318 \n",
      "Q 0+602   T 602  ☑ 602 \n",
      "Q 96+7    T 103  ☑ 103 \n",
      "Q 491+995 T 1486 ☑ 1486\n",
      "Q 852+16  T 868  ☑ 868 \n",
      "Q 719+886 T 1605 ☑ 1605\n",
      "Q 386+413 T 799  ☑ 799 \n",
      "Q 8+722   T 730  ☑ 730 \n",
      "\n",
      "Iteration 22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 32s 23ms/step - loss: 0.0181 - accuracy: 0.9955 - val_loss: 0.0077 - val_accuracy: 0.9984\n",
      "Q 275+19  T 294  ☑ 294 \n",
      "Q 85+998  T 1083 ☑ 1083\n",
      "Q 879+5   T 884  ☑ 884 \n",
      "Q 66+507  T 573  ☑ 573 \n",
      "Q 1+729   T 730  ☑ 730 \n",
      "Q 7+310   T 317  ☑ 317 \n",
      "Q 491+995 T 1486 ☑ 1486\n",
      "Q 59+515  T 574  ☑ 574 \n",
      "Q 469+11  T 480  ☑ 480 \n",
      "Q 586+694 T 1280 ☑ 1280\n",
      "\n",
      "Iteration 23\n",
      "1407/1407 [==============================] - 32s 23ms/step - loss: 0.0305 - accuracy: 0.9910 - val_loss: 0.0134 - val_accuracy: 0.9966\n",
      "Q 657+411 T 1068 ☑ 1068\n",
      "Q 395+505 T 900  ☑ 900 \n",
      "Q 104+98  T 202  ☑ 202 \n",
      "Q 928+473 T 1401 ☑ 1401\n",
      "Q 622+0   T 622  ☑ 622 \n",
      "Q 607+191 T 798  ☒ 898 \n",
      "Q 325+546 T 871  ☑ 871 \n",
      "Q 90+59   T 149  ☑ 149 \n",
      "Q 92+814  T 906  ☑ 906 \n",
      "Q 642+679 T 1321 ☑ 1321\n",
      "\n",
      "Iteration 24\n",
      "1407/1407 [==============================] - 32s 23ms/step - loss: 0.0157 - accuracy: 0.9958 - val_loss: 0.0074 - val_accuracy: 0.9987\n",
      "Q 74+936  T 1010 ☑ 1010\n",
      "Q 920+526 T 1446 ☑ 1446\n",
      "Q 88+847  T 935  ☑ 935 \n",
      "Q 893+901 T 1794 ☑ 1794\n",
      "Q 803+989 T 1792 ☑ 1792\n",
      "Q 80+849  T 929  ☑ 929 \n",
      "Q 434+17  T 451  ☑ 451 \n",
      "Q 632+9   T 641  ☑ 641 \n",
      "Q 390+142 T 532  ☑ 532 \n",
      "Q 491+995 T 1486 ☑ 1486\n",
      "\n",
      "Iteration 25\n",
      "1407/1407 [==============================] - 33s 23ms/step - loss: 0.0208 - accuracy: 0.9943 - val_loss: 0.0138 - val_accuracy: 0.9970\n",
      "Q 721+770 T 1491 ☑ 1491\n",
      "Q 682+202 T 884  ☑ 884 \n",
      "Q 29+901  T 930  ☑ 930 \n",
      "Q 40+230  T 270  ☑ 270 \n",
      "Q 803+95  T 898  ☑ 898 \n",
      "Q 63+121  T 184  ☑ 184 \n",
      "Q 23+30   T 53   ☑ 53  \n",
      "Q 891+826 T 1717 ☑ 1717\n",
      "Q 530+78  T 608  ☑ 608 \n",
      "Q 10+848  T 858  ☑ 858 \n",
      "\n",
      "Iteration 26\n",
      "1407/1407 [==============================] - 33s 23ms/step - loss: 0.0143 - accuracy: 0.9964 - val_loss: 0.0737 - val_accuracy: 0.9780\n",
      "Q 68+223  T 291  ☑ 291 \n",
      "Q 18+965  T 983  ☑ 983 \n",
      "Q 55+561  T 616  ☑ 616 \n",
      "Q 676+18  T 694  ☑ 694 \n",
      "Q 73+831  T 904  ☑ 904 \n",
      "Q 148+10  T 158  ☑ 158 \n",
      "Q 288+68  T 356  ☑ 356 \n",
      "Q 26+54   T 80   ☑ 80  \n",
      "Q 8+307   T 315  ☑ 315 \n",
      "Q 95+776  T 871  ☑ 871 \n",
      "\n",
      "Iteration 27\n",
      "1407/1407 [==============================] - 33s 23ms/step - loss: 0.0131 - accuracy: 0.9967 - val_loss: 0.0126 - val_accuracy: 0.9965\n",
      "Q 93+5    T 98   ☑ 98  \n",
      "Q 753+372 T 1125 ☑ 1125\n",
      "Q 277+1   T 278  ☑ 278 \n",
      "Q 379+466 T 845  ☑ 845 \n",
      "Q 379+607 T 986  ☑ 986 \n",
      "Q 249+76  T 325  ☑ 325 \n",
      "Q 802+72  T 874  ☑ 874 \n",
      "Q 990+6   T 996  ☑ 996 \n",
      "Q 426+96  T 522  ☑ 522 \n",
      "Q 659+71  T 730  ☑ 730 \n",
      "\n",
      "Iteration 28\n",
      "1407/1407 [==============================] - 32s 22ms/step - loss: 0.0164 - accuracy: 0.9958 - val_loss: 0.0035 - val_accuracy: 0.9994\n",
      "Q 33+239  T 272  ☑ 272 \n",
      "Q 907+79  T 986  ☑ 986 \n",
      "Q 486+756 T 1242 ☑ 1242\n",
      "Q 44+99   T 143  ☑ 143 \n",
      "Q 603+963 T 1566 ☑ 1566\n",
      "Q 228+49  T 277  ☑ 277 \n",
      "Q 226+950 T 1176 ☑ 1176\n",
      "Q 7+829   T 836  ☑ 836 \n",
      "Q 921+53  T 974  ☑ 974 \n",
      "Q 939+165 T 1104 ☑ 1104\n",
      "\n",
      "Iteration 29\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0245 - accuracy: 0.9936 - val_loss: 0.0047 - val_accuracy: 0.9990\n",
      "Q 65+25   T 90   ☑ 90  \n",
      "Q 928+58  T 986  ☑ 986 \n",
      "Q 962+34  T 996  ☑ 996 \n",
      "Q 57+457  T 514  ☑ 514 \n",
      "Q 178+39  T 217  ☑ 217 \n",
      "Q 846+77  T 923  ☑ 923 \n",
      "Q 361+2   T 363  ☑ 363 \n",
      "Q 275+11  T 286  ☑ 286 \n",
      "Q 385+252 T 637  ☑ 637 \n",
      "Q 696+8   T 704  ☑ 704 \n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "# Train the model each generation and show predictions against the validation\n",
    "# dataset.\n",
    "for epoch in range(1, epochs):\n",
    "    print()\n",
    "    print(\"Iteration\", epoch)\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=1,\n",
    "        validation_data=(x_val, y_val),\n",
    "    )\n",
    "    # Select 10 samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = np.argmax(model.predict(rowx), axis=-1)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print(\"Q\", q[::-1] if REVERSE else q, end=\" \")\n",
    "        print(\"T\", correct, end=\" \")\n",
    "        if correct == guess:\n",
    "            print(\"☑ \" + guess)\n",
    "        else:\n",
    "            print(\"☒ \" + guess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
