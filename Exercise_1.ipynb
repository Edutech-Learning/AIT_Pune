{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 - MNIST CLASSIFIER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST is a standard dataset used for classification task. This dataset consists of lots of images of handwritten digits. The task is to classify each image according to the number they represent "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependancies\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the hyperparameters\n",
    "In the cell below, we shall set the different parameters of the model. These are user defined and you are encouraged to experiment with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config cell\n",
    "num_classes = 10          #number of classes(0 to 9)  \n",
    "input_shape = (28, 28, 1) #shape of an image\n",
    "batch_size = 128          #How many images to train in one iteration\n",
    "epochs = 15               #Number of times the model gets trained on the entire dataset \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading, Visualization and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAANOklEQVR4nO3db6hc9Z3H8c9n3QaiLTGabLik0XSLCGXRdA1hoTHJWls1CDd5Is2DkhXZW6SuDfbBigaaBz4Q2TasPiikKkm0aymmwYvI2mwo3vRJMUrW/G0Ta0ITYv4gWEseZGO+++CelGu885ubmTNz5ub7fsFlZs53zpyvg5+cmfmdc36OCAG4+v1N0w0A6A/CDiRB2IEkCDuQBGEHkvjbfm7MNj/9Az0WEZ5seVd7dtv32v697SO2H+/mtQD0ljsdZ7d9jaQ/SPqWpOOS3pa0JiIOFNZhzw70WC/27EskHYmIP0bEeUm/kDTcxesB6KFuwj5f0p8mPD5eLfsM2yO2d9ve3cW2AHSp5z/QRcQmSZskPsYDTepmz35C0oIJj79cLQMwgLoJ+9uSbrH9FdszJH1H0mg9bQGoW8cf4yPigu1HJL0p6RpJL0bE/to6A1CrjofeOtoY39mBnuvJQTUApg/CDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBIdz88uSbaPSvpE0qeSLkTE4jqaAlC/rsJe+eeIOFvD6wDoIT7GA0l0G/aQ9Gvb79gemewJtkds77a9u8ttAeiCI6Lzle35EXHC9t9J2iHp3yJirPD8zjcGYEoiwpMt72rPHhEnqtvTkrZLWtLN6wHonY7Dbvs621+6dF/StyXtq6sxAPXq5tf4eZK22770Ov8VEf9dS1cAatfVd/Yr3hjf2YGe68l3dgDTB2EHkiDsQBKEHUiCsANJ1HEiDNCRhQsXFusPPvhgsb5+/fpifdeuXS1rw8PDxXU//vjjYn06Ys8OJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0lw1ltyc+fOLdbvu+++Yv3JJ58s1qtToCc1c+bM4rpDQ0PFejulbW/durW4brsx/kHGWW9AcoQdSIKwA0kQdiAJwg4kQdiBJAg7kATns08DM2bMKNZvuummlrVnn322uO6NN95YrN9xxx3Fejulse5+HuNxuW3btjW27aawZweSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhnHwClsWhJeuyxx4r1p556quPXbnKsu0kHDx5suoW+a7tnt/2i7dO2901YdoPtHbYPV7eze9smgG5N5WP8Zkn3XrbscUk7I+IWSTurxwAGWNuwR8SYpI8uWzwsaUt1f4ukVTX3BaBmnX5nnxcRJ6v7H0qa1+qJtkckjXS4HQA16foHuoiI0oUkI2KTpE0SF5wEmtTp0Nsp20OSVN2erq8lAL3QadhHJa2t7q+V9Fo97QDolbYf422/ImmFpDm2j0v6kaSnJf3S9kOSjkl6oJdNDrrly5cX67fddlux3u7a63PmzLninuoyOjparB87dqxY37x5c8vam2++WVy32//u5557rmXt/fff7+q1p6O2YY+INS1K36y5FwA9xOGyQBKEHUiCsANJEHYgCcIOJMGUzVNUmrr45ZdfLq47a9asutv5jAMHDrSstRsaa3eq54YNG4r1c+fOFeunTp1qWWt3Get2Sv/dknTXXXe1rJ09e7arbQ8ypmwGkiPsQBKEHUiCsANJEHYgCcIOJEHYgSS4lPQUlY5HaHeswuHDh4v10qWgpfZjwocOHWpZazfO3q25c+cW66XTVNu9b+fPny/Wn3nmmWL9ah5L7wR7diAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgvPZa7Bs2bJifWxsrE+d1K/dOHq7y0HffvvtLWv79+8vrttuHL3ddQSy4nx2IDnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcXYUvfHGG8X6PffcU6zv3bu3Ze3uu+8ursv56J3peJzd9ou2T9veN2HZBtsnbO+p/lbW2SyA+k3lY/xmSfdOsnxjRCyq/sr//ANoXNuwR8SYpI/60AuAHurmB7pHbL9Xfcyf3epJtkds77a9u4ttAehSp2H/qaSvSlok6aSkH7d6YkRsiojFEbG4w20BqEFHYY+IUxHxaURclPQzSUvqbQtA3ToKu+2hCQ9XS9rX6rkABkPb68bbfkXSCklzbB+X9CNJK2wvkhSSjkr6Xg97RA89/PDDxfrSpUuL9XbHaZTG0hlH76+2YY+INZMsfqEHvQDoIQ6XBZIg7EAShB1IgrADSRB2IAlOcb3KDQ8PF+svvfRSsX7ttdcW62fOnCnWh4aGinXUj0tJA8kRdiAJwg4kQdiBJAg7kARhB5Ig7EASbc96w/S2bt26Yr3bcfR2l5LG4GDPDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMM4+DVx//fXF+vbt21vWVqxYUVz3gw8+KNZXrixP0Hvo0KFiHYODPTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJME4+zSwbNmyYv3OO+9sWbt48WJx3VdffbVYZxz96tF2z257ge3f2D5ge7/tH1TLb7C9w/bh6nZ279sF0KmpfIy/IOmHEfE1Sf8k6fu2vybpcUk7I+IWSTurxwAGVNuwR8TJiHi3uv+JpIOS5ksalrSletoWSat61SSA7l3Rd3bbCyV9XdLvJM2LiJNV6UNJ81qsMyJppPMWAdRhyr/G2/6ipG2S1kXEnyfWYnx2yEknbYyITRGxOCIWd9UpgK5MKey2v6DxoP88In5VLT5le6iqD0k63ZsWAdSh7cd425b0gqSDEfGTCaVRSWslPV3dvtaTDhN4/vnni/X777+/49ceHR0t1jds2NDxa2N6mcp39m9I+q6kvbb3VMue0HjIf2n7IUnHJD3QmxYB1KFt2CPit5Imndxd0jfrbQdAr3C4LJAEYQeSIOxAEoQdSIKwA0lwimsfLF++vFhfvXp1sT5r1qyOt71x48Zi/dy5cx2/NqYX9uxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kITHLzLTp43Z/dtYH42f8t/ahQsXunr9I0eOFOu33nprV6+Pq0tETPo/JHt2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiC89lrsH79+mK93bEMZ86cKdYfffTRK+4JuBx7diAJwg4kQdiBJAg7kARhB5Ig7EAShB1Iou357LYXSNoqaZ6kkLQpIv7T9gZJ/yrp0iDxExHxRpvXmrbns8+fP79lbWxsrLjuzTffXKyvWrWqWH/99deLdWCiVuezT+WgmguSfhgR79r+kqR3bO+oahsj4j/qahJA70xlfvaTkk5W9z+xfVBS690cgIF0Rd/ZbS+U9HVJv6sWPWL7Pdsv2p7dYp0R27tt7+6qUwBdmXLYbX9R0jZJ6yLiz5J+KumrkhZpfM//48nWi4hNEbE4IhbX0C+ADk0p7La/oPGg/zwifiVJEXEqIj6NiIuSfiZpSe/aBNCttmH3+KVTX5B0MCJ+MmH50ISnrZa0r/72ANRlKr/Gf0PSdyXttb2nWvaEpDW2F2l8OO6opO/1pMMBMXPmzJa1dkNrb731VrG+a9eujnoCrsRUfo3/raTJxu2KY+oABgtH0AFJEHYgCcIOJEHYgSQIO5AEYQeSYMpm4CrDlM1AcoQdSIKwA0kQdiAJwg4kQdiBJAg7kES/p2w+K+nYhMdzqmWDaFB7G9S+JHrrVJ29tby4Ql8Pqvncxu3dg3ptukHtbVD7kuitU/3qjY/xQBKEHUii6bBvanj7JYPa26D2JdFbp/rSW6Pf2QH0T9N7dgB9QtiBJBoJu+17bf/e9hHbjzfRQyu2j9rea3tP0/PTVXPonba9b8KyG2zvsH24up10jr2Gettg+0T13u2xvbKh3hbY/o3tA7b32/5BtbzR967QV1/et75/Z7d9jaQ/SPqWpOOS3pa0JiIO9LWRFmwflbQ4Iho/AMP2Mkl/kbQ1Iv6hWvaMpI8i4unqH8rZEfHvA9LbBkl/aXoa72q2oqGJ04xLWiXpX9Tge1fo6wH14X1rYs++RNKRiPhjRJyX9AtJww30MfAiYkzSR5ctHpa0pbq/ReP/s/Rdi94GQkScjIh3q/ufSLo0zXij712hr75oIuzzJf1pwuPjGqz53kPSr22/Y3uk6WYmMS8iTlb3P5Q0r8lmJtF2Gu9+umya8YF57zqZ/rxb/ED3eUsj4h8l3Sfp+9XH1YEU49/BBmnsdErTePfLJNOM/1WT712n0593q4mwn5C0YMLjL1fLBkJEnKhuT0varsGbivrUpRl0q9vTDffzV4M0jfdk04xrAN67Jqc/byLsb0u6xfZXbM+Q9B1Jow308Tm2r6t+OJHt6yR9W4M3FfWopLXV/bWSXmuwl88YlGm8W00zrobfu8anP4+Ivv9JWqnxX+Tfl/RkEz206OvvJf1v9be/6d4kvaLxj3X/p/HfNh6SdKOknZIOS/ofSTcMUG8vSdor6T2NB2uood6Wavwj+nuS9lR/K5t+7wp99eV943BZIAl+oAOSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJP4f4HgzBVY3NFsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "#visualize the 79th image of the dataset. You can change this value to get an idea about different images\n",
    "plt.imshow(x_train[79],cmap='gray')  \n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Build the model\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "422/422 [==============================] - 14s 33ms/step - loss: 0.3718 - accuracy: 0.8858 - val_loss: 0.0826 - val_accuracy: 0.9782\n",
      "Epoch 2/15\n",
      "422/422 [==============================] - 14s 32ms/step - loss: 0.1166 - accuracy: 0.9637 - val_loss: 0.0592 - val_accuracy: 0.9835\n",
      "Epoch 3/15\n",
      "422/422 [==============================] - 14s 34ms/step - loss: 0.0876 - accuracy: 0.9736 - val_loss: 0.0465 - val_accuracy: 0.9867\n",
      "Epoch 4/15\n",
      "422/422 [==============================] - 14s 34ms/step - loss: 0.0743 - accuracy: 0.9773 - val_loss: 0.0473 - val_accuracy: 0.9848\n",
      "Epoch 5/15\n",
      "422/422 [==============================] - 15s 36ms/step - loss: 0.0647 - accuracy: 0.9799 - val_loss: 0.0423 - val_accuracy: 0.9865\n",
      "Epoch 6/15\n",
      "422/422 [==============================] - 15s 35ms/step - loss: 0.0585 - accuracy: 0.9817 - val_loss: 0.0387 - val_accuracy: 0.9880\n",
      "Epoch 7/15\n",
      "422/422 [==============================] - 15s 35ms/step - loss: 0.0549 - accuracy: 0.9821 - val_loss: 0.0390 - val_accuracy: 0.9890\n",
      "Epoch 8/15\n",
      "422/422 [==============================] - 15s 35ms/step - loss: 0.0503 - accuracy: 0.9845 - val_loss: 0.0384 - val_accuracy: 0.9890\n",
      "Epoch 9/15\n",
      "422/422 [==============================] - 15s 36ms/step - loss: 0.0480 - accuracy: 0.9852 - val_loss: 0.0318 - val_accuracy: 0.9913\n",
      "Epoch 10/15\n",
      "422/422 [==============================] - 15s 36ms/step - loss: 0.0445 - accuracy: 0.9858 - val_loss: 0.0329 - val_accuracy: 0.9900\n",
      "Epoch 11/15\n",
      "422/422 [==============================] - 15s 35ms/step - loss: 0.0419 - accuracy: 0.9865 - val_loss: 0.0300 - val_accuracy: 0.9907\n",
      "Epoch 12/15\n",
      "422/422 [==============================] - 15s 35ms/step - loss: 0.0402 - accuracy: 0.9868 - val_loss: 0.0317 - val_accuracy: 0.9915\n",
      "Epoch 13/15\n",
      "422/422 [==============================] - 15s 35ms/step - loss: 0.0380 - accuracy: 0.9871 - val_loss: 0.0303 - val_accuracy: 0.9917\n",
      "Epoch 14/15\n",
      "422/422 [==============================] - 16s 37ms/step - loss: 0.0355 - accuracy: 0.9885 - val_loss: 0.0293 - val_accuracy: 0.9920\n",
      "Epoch 15/15\n",
      "422/422 [==============================] - 16s 39ms/step - loss: 0.0338 - accuracy: 0.9889 - val_loss: 0.0272 - val_accuracy: 0.9930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f52d04540b8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compile the model with a loss function, optimizer and an evaluation metric\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "#Train the model, with 10% of the data being the validation set\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.024955153465270996\n",
      "Test accuracy: 0.9908999800682068\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label:  5\n",
      "Correct Label:  5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#view an image and the predicted label. Encouraged to experiment\n",
    "test_img = x_test[129]\n",
    "correct_label = y_test[129]\n",
    "predicted_label = model.predict(np.expand_dims(test_img, 0))\n",
    "plt.imshow(test_img[:,:,0],cmap='gray')\n",
    "print(\"Predicted Label: \",np.argmax(predicted_label))\n",
    "print(\"Correct Label: \",np.argmax(correct_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
